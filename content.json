{"meta":{"title":"Tango","subtitle":"探戈","description":"最不稀罕的东西：不在乎人的赞美，不喜欢人的殷勤，还有你无差别对待的好","author":"FaderW","url":"www.google.com"},"pages":[{"title":"about","date":"2018-08-09T18:05:14.000Z","updated":"2018-08-25T14:18:35.149Z","comments":true,"path":"about/index.html","permalink":"www.google.com/about/index.html","excerpt":"","text":"个人简介 nickname:FaderW industry: Java programmers email: wyx19950516@163.com"},{"title":"分类","date":"2017-07-21T09:00:14.000Z","updated":"2018-08-25T14:18:35.149Z","comments":true,"path":"categories/index.html","permalink":"www.google.com/categories/index.html","excerpt":"","text":""},{"title":"history","date":"2018-08-09T17:52:54.000Z","updated":"2018-08-25T14:18:35.165Z","comments":true,"path":"history/index.html","permalink":"www.google.com/history/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-12-29T15:45:38.000Z","updated":"2018-08-25T14:18:35.165Z","comments":true,"path":"tags/index.html","permalink":"www.google.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Venus","slug":"Venus","date":"2018-08-25T21:35:39.000Z","updated":"2018-08-25T14:18:35.149Z","comments":true,"path":"2018/08/25/Venus/","link":"","permalink":"www.google.com/2018/08/25/Venus/","excerpt":"","text":"轻量级爬虫框架Venus核心组件 Downloader(网页下载器) Spider(爬虫处理器) Scheduler(调度器) Parser(网页解析器) Pipline(数据处理器) Engine(流转引擎) 具体介绍Downloader网页下载器，顾名思义，就是从网络上下载数据，也就是爬虫的根本事件。给定一个或一组url,进行http请求，获取我们想要的数据（json、html、xml等）。而编写http请求的过程往往是重复的，所以应当进行封装以通用。 1234567891011121314151617181920212223242526272829303132public class Downloader implements Runnable&#123; private final Scheduler Scheduler; private final Request request; public Downloader(Scheduler scheduler, Request request) &#123; this.Scheduler = scheduler; this.request = request; &#125; @Override public void run() &#123; log.info(\"start request url &#123;&#125;\", request.getUrl()); HttpRequest httpRequest = null; if (\"get\".equalsIgnoreCase(request.getMethod())) &#123; httpRequest = HttpRequest.get(request.getUrl()); &#125; else if (\"post\".equalsIgnoreCase(request.getMethod())) &#123; httpRequest = HttpRequest.post(request.getUrl()); &#125; else &#123; log.error(\"method &#123;&#125; 无效\", request.getMethod()); &#125; InputStream inputStream = httpRequest.contentType(request.contentType()) .headers(request.headers()).connectTimeout(request.getSpider().getConfig().timeout()) .readTimeout(request.getSpider().getConfig().timeout()).stream(); log.info(\"download has finsihed url &#123;&#125;\", request.getUrl()); Response response = new Response(request, inputStream); Scheduler.addResponse(response); &#125;&#125; 一个Downloader就是一个线程,Request对象封装了请求的信息，包括url、header等，请求完后，获取一个包含了返回数据的流，这里不作处理，直接构造一个response对象，然后压入到Scheduler（调取器）的返回队列中去。交给后续的爬虫处理器以及解析器来处理。 Scheduler调取器，就是调度请求与返回的，在解析器与下载器之间进行流转，解析器解析新的url加入请求队列中，调度器再生成新的下载器进行下载。 12private BlockingQueue&lt;Request&gt; pending = Queues.newLinkedBlockingQueue();private BlockingQueue&lt;Response&gt; processed = Queues.newLinkedBlockingQueue(); Scheduler中有两个队列，待爬取的Request和已爬取的Response。Scheduler提供入队和出队操作，供其他组件进行调用。 Spider爬虫处理器，用于对爬取的数据进行处理，比如说入库、写文件等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public abstract class Spider &#123; protected Config config; protected String name; protected List&lt;String&gt; startUrls = Lists.newArrayList(); protected List&lt;Request&gt; requests = Lists.newArrayList(); protected List&lt;Pipeline&gt; pipelines = Lists.newArrayList(); public void setConfig(Config config) &#123; this.config = config; &#125; public Config getConfig() &#123; return this.config; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return this.name; &#125; public List&lt;Pipeline&gt; getPipelines() &#123; return this.pipelines; &#125; public void setPipelines(List&lt;Pipeline&gt; pipelines) &#123; this.pipelines = pipelines; &#125; public Spider() &#123; &#125; public Spider(String name) &#123; this.name = name; EventManager.registerEvent(EventManager.VenusEvent.SPIDER_STARTED, this::onStart); &#125; public List&lt;String&gt; getStartUrls() &#123; return this.startUrls; &#125; public Spider startUrls(String... urls) &#123; this.startUrls.addAll(Arrays.asList(urls)); return this; &#125; public List&lt;Request&gt; getRequests() &#123; return this.requests; &#125; /** * 爬虫启动前执行 */ public abstract void onStart(Config config); protected &lt;T&gt; Spider addPipline(Pipeline&lt;T&gt; pipeline) &#123; this.pipelines.add(pipeline); return this; &#125; /** * 构建一个request */ public &lt;T&gt; Request&lt;T&gt; makeRequest(String url) &#123; return makeRequest(url, this::parse); &#125; public &lt;T&gt; Request&lt;T&gt; makeRequest(String url, Parser&lt;T&gt; parser) &#123; return new Request&lt;&gt;(this, url, parser); &#125; /** * 解析DOM * 子类需要实现此方法 */ protected abstract &lt;T&gt; Result&lt;T&gt; parse(Response response); protected void resetRequest(Consumer&lt;Request&gt; consumer) &#123; this.resetRequest(this.requests, consumer); &#125; protected void resetRequest(List&lt;Request&gt; requests, Consumer&lt;Request&gt; consumer) &#123; requests.forEach(consumer::accept); &#125;&#125; param-startUrls 抽象类Spider维护了一个url集合，用于接受爬虫原始的url，进一步封装成request对象 method-parse 抽象方法，子类实现该方法定义自己的解析操作 param-pipeline 管道集合，进行数据处理的类，类似管道 Engine整个爬虫流程的核心控制器，流转引擎 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class VenusEngine &#123; private List&lt;Spider&gt; spiders; private Config config; private Scheduler scheduler; private ExecutorService executorService; private boolean isRunning; public VenusEngine(Venus venus) &#123; this.spiders = venus.spiders; this.config = venus.config; this.scheduler = new Scheduler(); this.executorService = new ThreadPoolExecutor(config.parallelThreads(), config.parallelThreads(), 60L, TimeUnit.MILLISECONDS, config.queueSize() == 0 ? new SynchronousQueue&lt;&gt;() : (config.queueSize() &lt; 0 ? new LinkedBlockingQueue&lt;&gt;() : new LinkedBlockingQueue&lt;&gt;(config.queueSize())), new ThreadFactoryBuilder().setNameFormat(\"task-thread-%d\").build()); &#125; public void start() &#123; if (isRunning) &#123; throw new RuntimeException(\"Venus 已经启动\"); &#125; isRunning = true; log.info(\"全局启动事件\"); EventManager.fireEvent(VenusEvent.GLOBAL_STARTED, this.config); spiders.forEach(spider -&gt; &#123; // 使用克隆为每个spider对象设置一个config属性 Config config = this.config.clone(); spider.setConfig(config); List&lt;Request&gt; requests = spider.getStartUrls().stream() .map(spider::makeRequest).collect(Collectors.toList()); spider.getRequests().addAll(requests); scheduler.addRequest(requests); EventManager.fireEvent(VenusEvent.SPIDER_STARTED, this.config); &#125;); // 开启一个线程来不断扫描是否有带爬取的Request Thread downloadThread = new Thread(() -&gt; &#123; while (isRunning) &#123; if (!scheduler.hasRequest()) &#123; VenusUtils.sleep(100); continue; &#125; Request request = scheduler.nextRequest(); executorService.submit(new Downloader(scheduler, request)); VenusUtils.sleep(request.getSpider().getConfig().Delay()); &#125; &#125;); downloadThread.setDaemon(true); downloadThread.setName(\"download-thread\"); downloadThread.start(); //消费 this.complete(); &#125; private void complete() &#123; while (isRunning) &#123; if (!scheduler.hasResponse()) &#123; VenusUtils.sleep(100); continue; &#125; Response response = scheduler.nextResponse(); Parser parser = response.getRequest().getParser(); if (null != parser) &#123; Result&lt;?&gt; result = parser.parse(response); List&lt;Request&gt; requests = result.getRequests(); if (!VenusUtils.isEmpty(requests)) &#123; requests.forEach(scheduler::addRequest); &#125; if (null != result.getItem()) &#123; List&lt;Pipeline&gt; pipelines = response.getRequest().getSpider().getPipelines(); pipelines.forEach(pipeline -&gt; pipeline.process(result.getItem(), response.getRequest())); &#125; &#125; &#125; &#125;&#125; 流转引擎主要分为以下几个步骤： 遍历spider集合，构建request，压入调度器，同时消费爬虫启动事件。 开启一个线程来专门从调取器中获取待处理的request，创建相应的下载器去下载。 消费response,这里分为两步parser和pipeline，解析和处理。 Parser网页解析器，对元数据进行解析，提取我们所需的信息，转换成对应的对象。 12345public interface Parser&lt;T&gt; &#123; Result&lt;T&gt; parse(Response response); &#125; 实现该方法编写自己的解析逻辑 Pipeline数据处理器，pipeline有管道的意思，解析器完成解析后，把解析的结果扔进数据处理管道中进行处理。是入库，写文件还是打印等等。 1234public interface Pipeline&lt;T&gt; &#123; void process(T item, Request&lt;?&gt; Request);&#125;","categories":[{"name":"Java","slug":"Java","permalink":"www.google.com/categories/Java/"}],"tags":[{"name":"spider、framework","slug":"spider、framework","permalink":"www.google.com/tags/spider、framework/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-08-25T14:18:35.149Z","updated":"2018-08-25T14:18:35.149Z","comments":true,"path":"2018/08/25/hello-world/","link":"","permalink":"www.google.com/2018/08/25/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"使用AOP实现日志切入","slug":"LogAspect","date":"2017-12-29T15:24:18.000Z","updated":"2018-08-25T14:18:35.149Z","comments":true,"path":"2017/12/29/LogAspect/","link":"","permalink":"www.google.com/2017/12/29/LogAspect/","excerpt":"","text":"定义@Cache注解1234567@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Inheritedpublic @interface Cache &#123; int value() default 0;&#125; 定义日志配置类12345@Configuration@ComponentScan@EnableAspectJAutoProxy(proxyTargetClass = true)public class PeopleConfig &#123;&#125; 定义People接口与Man实现类123456789101112131415161718public interface People &#123; /** * @param name * say hello */ void sayHello(String name);&#125;@Componentpublic class Man implements People &#123; @Override @Cache(1) public void sayHello(String name) &#123; System.out.println(\"Hello, I am Man, My name is : \" + name); &#125;&#125; 定义日志切面类1234567891011121314151617181920212223@Component@Aspect@Order(1000)public class LogAspect &#123; //定义切入点,使用Cache注解的方法 @Pointcut(\"@annotation(Cache)\") private void cache()&#123;&#125; //定义环绕通知 @Around(\"cache()\") private Object logAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable &#123; Object args = proceedingJoinPoint.getArgs(); System.out.println(\"args:\" + JSONObject.toJSONString(args)); return proceedingJoinPoint.proceed(); &#125; public static void main(String[] args) &#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext(PeopleConfig.class); Man man = applicationContext.getBean(\"man\", Man.class); man.sayHello(\"FaderWang\"); &#125;&#125; 测试运行结果12args:[\"FaderWang\"]Hello, I am Man, My name is : FaderWang","categories":[{"name":"Java","slug":"Java","permalink":"www.google.com/categories/Java/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"www.google.com/tags/AOP/"}]},{"title":"使用java NIO实现一个echo server","slug":"echo-server","date":"2017-12-19T19:34:13.000Z","updated":"2018-08-25T14:18:35.149Z","comments":true,"path":"2017/12/19/echo-server/","link":"","permalink":"www.google.com/2017/12/19/echo-server/","excerpt":"使用Java NIO来实现一个简单的echo server服务器，以代码为主\u001c","text":"使用Java NIO来实现一个简单的echo server服务器，以代码为主\u001c 客户端代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class Client &#123; private Selector selector; private SocketChannel socketChannel; /** * 服务器地址 */ private String hostIp; /** * 监听端口 */ private int listenPort; public Client(String hostIp, int listenPort) throws IOException &#123; this.hostIp = hostIp; this.listenPort = listenPort; initialize(); &#125; private void initialize() throws IOException &#123; //开启监听通道，设置为非阻塞模式 socketChannel = SocketChannel.open(new InetSocketAddress(hostIp, listenPort)); socketChannel.configureBlocking(false); //打开选择器，并注册通道 selector = Selector.open(); socketChannel.register(selector, SelectionKey.OP_READ); ExecutorService executorService = Executors.newSingleThreadExecutor(); executorService.submit(() -&gt; &#123; try &#123; while (selector.select() &gt; 0) &#123; Iterator&lt;SelectionKey&gt; keyIterator = selector.selectedKeys().iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isReadable()) &#123; SocketChannel channel = (SocketChannel) key.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); channel.read(byteBuffer); byteBuffer.flip(); String receive = Charset.forName(\"UTF-8\").newDecoder().decode(byteBuffer).toString(); System.out.println(\"接收到来自服务器的消息：\" + receive); System.out.println(\"服务器地址：\" + channel.socket().getRemoteSocketAddress()); key.interestOps(SelectionKey.OP_READ); &#125; keyIterator.remove(); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;); &#125; public void sendMsg(String message) throws IOException &#123; ByteBuffer byteBuffer = ByteBuffer.wrap(message.getBytes(\"UTF-8\")); socketChannel.write(byteBuffer); &#125; public static void main(String[] args) throws IOException &#123; Client client = new Client(\"192.168.5.111\", 1978); client.sendMsg(\"你好NIO, I am FaderWang\"); &#125; 服务端代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Server &#123; //缓冲区大小 private static final int BUFFER_SIZE = 1024; //超时时间 private static final int TIME_OUT = 3000; private ServerSocketChannel serverSocketChannel; private Selector selector; /** * 本地监听端口 */ private int listenPort; public Server(int listenPort) throws IOException &#123; this.listenPort = listenPort; initialize(); &#125; public void initialize() throws IOException &#123; //打开监听通道并绑定端口 serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(listenPort)); serverSocketChannel.configureBlocking(false); //开启选择器并注册通道 selector = Selector.open(); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); //创建一个处理协议实现类 TCPHandler tcpHandler = new TCPHandlerImpl(BUFFER_SIZE); while (true) &#123; if (selector.select(TIME_OUT) == 0) &#123; System.out.println(\"独自等待\"); continue; &#125; Iterator&lt;SelectionKey&gt; keyIterator = selector.selectedKeys().iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); try &#123; if (key.isAcceptable()) &#123; tcpHandler.handleAccept(key); &#125; if (key.isReadable()) &#123; tcpHandler.handleRead(key); &#125; &#125; catch (Exception e) &#123; keyIterator.remove(); &#125; &#125; &#125; &#125; public static void main(String[] args) throws IOException &#123; Server server = new Server(1978); &#125; 服务端处理类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public interface TCPHandler &#123; /** * 处理接收 * @param key */ void handleAccept(SelectionKey key) throws Exception; /** * 处理写入 * @param key */ void handleWrite(SelectionKey key); /** * 处理读出 * @param key */ void handleRead(SelectionKey key) throws IOException;&#125;public class TCPHandlerImpl implements TCPHandler &#123; private int bufferSize; public TCPHandlerImpl(int bufferSize) &#123; this.bufferSize = bufferSize; &#125; @Override public void handleAccept(SelectionKey key) throws Exception &#123; SocketChannel socketChannel = ((ServerSocketChannel) key.channel()).accept(); socketChannel.configureBlocking(false); Selector selector = key.selector(); socketChannel.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(bufferSize)); &#125; @Override public void handleWrite(SelectionKey key) &#123; return; &#125; @Override public void handleRead(SelectionKey key) throws IOException &#123; SocketChannel socketChannel = (SocketChannel) key.channel(); //得到缓冲区 ByteBuffer byteBuffer = (ByteBuffer) key.attachment(); byteBuffer.clear(); if (socketChannel.read(byteBuffer) == -1) &#123; socketChannel.close(); &#125; else &#123; byteBuffer.flip(); String receive = Charset.forName(\"UTF-8\").newDecoder().decode(byteBuffer).toString(); System.out.println(\"接收到来自客户端的消息：\" + receive); System.out.println(\"客户端地址：\" + socketChannel.socket().getRemoteSocketAddress()); String send = \"你好，客户端\" + new Date().toString() + \",已收到你的消息\"; byteBuffer = ByteBuffer.wrap(send.getBytes(\"UTF-8\")); socketChannel.write(byteBuffer); //设置为下一次读取或写入做准备 key.interestOps(SelectionKey.OP_READ); &#125; &#125;&#125;","categories":[{"name":"IO","slug":"IO","permalink":"www.google.com/categories/IO/"}],"tags":[{"name":"echo server","slug":"echo-server","permalink":"www.google.com/tags/echo-server/"}]},{"title":"Apache Commons类库","slug":"Apache-Common-Study","date":"2017-07-20T19:39:41.000Z","updated":"2018-08-25T14:18:35.149Z","comments":true,"path":"2017/07/20/Apache-Common-Study/","link":"","permalink":"www.google.com/2017/07/20/Apache-Common-Study/","excerpt":"Apache common提供了很多强大的工具集，简化了Java开发人员的开发。下面是我个人一些使用心得。","text":"Apache common提供了很多强大的工具集，简化了Java开发人员的开发。下面是我个人一些使用心得。 \b介绍下commons-lang3 jar类库下的一些常用工具集RandomStringUtils 生成随机串 123456789101112//生成随机指定长度的字符串RandomStringUtils.random(4);//生成指定字符指定长度的字符串RandomStringUtils.random(4,new char[]&#123;'a', 'b', 'c', 'd'&#125;);//生成指定长度的数字字符串RandomStringUtils.randomNumeric(4);//生成自定长度的Alpha字母串（a-z,A-Z）RandomStringUtils.randomAlphabetic(4);//生成指定长度的Alpha字母或数字串（a-z,A-z,0-9）RandomStringUtils.randomAlphanumeric(4);//获取指定长度的Ascii值在（32-126）的字符串RandomStringUtils.randomAscii(4); StringUtils 非空判断 12345678//判断是否为null或\"\"StringUtils.isNotEmpty(\"\");//判断是否为null或者\"\"(去空格)StringUtils.isNotBlank(\" \");//将null或\" \"转换为\"\"(空串)StringUtils.trimToEmpty(\" \");//将null或\"\"转换为nullStringUtils.trimToNull(\"\"); StringUtils分装的方法很多，这里就不一一列举，有兴趣可以查看文档","categories":[{"name":"Java","slug":"Java","permalink":"www.google.com/categories/Java/"}],"tags":[{"name":"Apache Commons","slug":"Apache-Commons","permalink":"www.google.com/tags/Apache-Commons/"}]}]}